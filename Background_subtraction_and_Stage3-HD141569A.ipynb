{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ab30bb-72aa-40e9-a420-fed85707ed54",
   "metadata": {},
   "source": [
    "# Background Subtraction and Stage 3 Processing\n",
    "\n",
    "- Author: J. Aguilar (jaguilar@stsci.edu)\n",
    "- Date: Aug 9, 2022\n",
    "\n",
    "\n",
    "The presence of glow sticks in the MIRI coronagraph means that, for the time being, users must acquire background observations and subtract them off their science observations to perform accurate PSF subtraction. This notebook will guide users through the process of:\n",
    "- Identifying which files are background observations\n",
    "- Combining and subtracting the backgrounds from the science observations\n",
    "- Running the new background-subtracted images through Stage 3 of the JWST calibration pipeline by creating a new asn file\n",
    "\n",
    "## Data\n",
    "The ERS data used in this tutorial are available at on MAST (mast.stsci.edu). The following link provides a shortcut: https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?searchQuery=%7B%22service%22%3A%22CAOMBYPROPID%22%2C%22inputText%22%3A%5B%7B%22paramName%22%3A%22proposal_id%22%2C%22niceName%22%3A%22proposal_id%22%2C%22values%22%3A%5B%221386%22%5D%2C%22valString%22%3A%221386%22%2C%22displayString%22%3A%221386%22%2C%22isDate%22%3Afalse%2C%22facetType%22%3A%22discrete%22%7D%5D%2C%22paramsService%22%3A%22Mast.Caom.Filtered%22%2C%22title%22%3A%22Proposal%20ID%20Results%22%2C%22columns%22%3A%22*%22%2C%22caomVersion%22%3Anull%7D\n",
    "\n",
    "## Non-standard lib requirements\n",
    "- `jwst` https://jwst-pipeline.readthedocs.io/\n",
    "- `astropy` https://docs.astropy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7856a-2200-4e03-93be-92bf8f6fe8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "print(\"Using pipeline version:\", jwst.__version__)\n",
    "from jwst.pipeline import Coron3Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb145b-ed7d-4c4d-844f-a61823b3eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82083634-8769-4e0e-937b-7b462ff61ad2",
   "metadata": {},
   "source": [
    "# Load the observations\n",
    "\n",
    "We're going to assume that there are `calints.fits` (aka Stage 2b) files available from MAST, but the backgrounds didn't get subtracted properly. If you only have `rateints.fits` (Stage 2a) or `uncal.fits` (Stage 1) files, refer to the pipeline documentation for how to process them up to stage 3.\n",
    "\n",
    "Set the variable `datapath` to wherever you downloaded the MAST data. I assume all the `.fits` files are in a single folder. If you have it set up differently, the important thing is that the variable `data_files` is a list of paths to the `calints.fits` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22536d4b-48d0-4de4-bd4a-90f71b30c2ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "datapath = Path(\"/Users/jaguilar/Projects/jwst_programs/mast_data/01386-2/01386/\")\n",
    "data_files = sorted(datapath.glob(\"j*calints.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362017b-2812-469d-979b-7e6801cbae0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enforce that all the members of data_files are pathlib.Paths\n",
    "for i, f in enumerate(data_files):\n",
    "    data_files[i] = Path(f)\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd71b96-8e33-4326-b566-d1d004aa1fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "308397ed-6ec5-419b-81e7-53e3018e1cd8",
   "metadata": {},
   "source": [
    "## Organize the science and background observations so you can subtract the appropriate ones from each other.\n",
    "\n",
    "We're going to use the observation number as the key for associating the background observations with their corresponding science observations.\n",
    "\n",
    "We'll store everything in dictionaries and use the file names and observation numbers to look things up.\n",
    "\n",
    "Files that have the same observation number are different dithers from the same observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a7647-1a56-42d3-9152-507ec711d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index them by the observation number\n",
    "obsnum_filenames = {f.name: Path(f).name[7:10] for f in data_files}\n",
    "obsnum_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0b957-a936-4a57-b65f-e86bbe007b36",
   "metadata": {},
   "source": [
    "# Match the background files\n",
    "\n",
    "Connect the science observations (target and reference) with their corresponding background observations\n",
    "Use the observation number from the APT file.\n",
    "Format is dict with key: val pairs as  {sci: bgnd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca69c925-70b0-496c-812e-0fe6631d044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the background exposures - there's one of each. \n",
    "# If science exposures have more than one associated background exposure, combine the backgrounds using min or median before subtracting\n",
    "bgnd_obsnums = ['032', '033', '034', '035', '036','037']\n",
    "bgnd_files  = {obsnum: [] for obsnum in bgnd_obsnums}\n",
    "for f, num in obsnum_filenames.items():\n",
    "    if num in bgnd_obsnums:\n",
    "        bgnd_files[num].append(f)\n",
    "    else:\n",
    "        pass\n",
    "bgnd_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e5c1a-4966-4ba2-b9a0-4ae1248fcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the background images\n",
    "bgnd_imgs = {}\n",
    "for num, files in bgnd_files.items():\n",
    "    img = np.stack([fits.getdata(datapath / f, 1) for f in files])\n",
    "    \n",
    "    # define the function you will use to combine the images. Here we use a simple one\n",
    "    func = np.nanmedian if len(files) > 2 else np.nanmin\n",
    "    img = func(img, axis=0)\n",
    "    \n",
    "    # flatten the background image until it's 2-D\n",
    "    while np.ndim(img) > 2:\n",
    "        img = np.nanmean(img, axis=0)\n",
    "    \n",
    "    bgnd_imgs[num] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700e965-7008-4b1a-9451-c84231dc5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgnd_imgs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2924fac-5d2e-47f6-8977-6c5e48d6d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgnd_matched_obsnums = {\n",
    "    # sci obs num : bgnd obs num\n",
    "    '019': '032',\n",
    "    '020': '032',\n",
    "    '021': '033',\n",
    "    '022': '034',\n",
    "    '023': '034',\n",
    "    '024': '035',\n",
    "    '025': '035',\n",
    "    '026': '036', \n",
    "    '027': '037',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c90c3-7869-423b-9042-9735c436df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the science images with their corresponding background images.\n",
    "# This convoluted inline expression just indexes all the dictionaries we've set up so far.\n",
    "# In the end we're left with a dictionary containing each matched pair. \n",
    "# The pair is stored in a dict where the science observation has key 'sci', \n",
    "# and the background observation has key 'bgnd'\n",
    "bgnd_matched_imgs = {sci_file: {'sci': fits.getdata(datapath / sci_file, 1), 'bgnd': bgnd_imgs[bgnd_matched_obsnums[sci_obsnum]]} \n",
    "                      for sci_file, sci_obsnum in obsnum_filenames.items() \n",
    "                      if sci_obsnum in bgnd_matched_obsnums.keys()\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67360824-7fda-4f7e-9803-3e7a3886130f",
   "metadata": {},
   "source": [
    "# Subtract the backgrounds\n",
    "\n",
    "Now that you have matched each science file with its background (and combined backgrounds if necessary), you can subtract them from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e0574-a9f9-4f45-b9c7-1d4f0a370606",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgnd_sub_imgs = {} # this will be indexed by the original filename\n",
    "for sci_file, pair in bgnd_matched_imgs.items():\n",
    "    sci_img = pair['sci']\n",
    "    bgnd_img = pair['bgnd']\n",
    "    # Subtract the background off. Since the bgnd is 2-D, the array shapes should automatically broadcast\n",
    "    img = sci_img - bgnd_img\n",
    "    bgnd_sub_imgs[sci_file] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cfbf5-abf8-43be-a1c9-9555b29c931e",
   "metadata": {},
   "source": [
    "## Preview the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc006dbb-2564-4afb-9d20-e17b2c2aa8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some observations have multiple dithers\n",
    "ncols = 3\n",
    "nrows = len(bgnd_matched_imgs)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "\n",
    "for i, (sci_file, pair) in enumerate(bgnd_matched_imgs.items()):\n",
    "    obsnum = sci_file[7:10]\n",
    "\n",
    "    # pull the images\n",
    "    sci_img = pair['sci']\n",
    "    bgnd_img = pair['bgnd']\n",
    "    bgsub_img = bgnd_sub_imgs[sci_file]\n",
    "    # reduce dimensions for plotting\n",
    "    while np.ndim(sci_img) > 2:\n",
    "        sci_img = np.nanmedian(sci_img, axis=0)\n",
    "    while np.ndim(bgnd_img) > 2:\n",
    "        bgnd_img = np.nanmedian(bgnd_img, axis=0)\n",
    "    while np.ndim(bgsub_img) > 2:\n",
    "        bgsub_img = np.nanmedian(bgsub_img, axis=0)\n",
    "\n",
    "    for img, ax in zip((sci_img, bgnd_img, bgsub_img), axes[i]):\n",
    "        vmin, vmax = np.quantile(img, [0.01, 0.99])\n",
    "        ax.imshow(img, vmin=vmin, vmax=vmax, origin='lower', cmap=mpl.cm.magma)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    axes[i, 0].set_ylabel(f\"Obs {obsnum}\", size='x-large')\n",
    "    axes[i, 1].set_ylabel(f\"Obs {bgnd_matched_obsnums[obsnum]}\", size='x-large')\n",
    "\n",
    "axes[0][0].set_title(\"Science\", size='x-large')\n",
    "axes[0][1].set_title(\"Background\", size='x-large');\n",
    "axes[0][2].set_title(\"Background Removed\", size='x-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc9e7a-d85b-4390-9790-37c670a2e20b",
   "metadata": {},
   "source": [
    "## Write images to file\n",
    "\n",
    "You can either replace the SCI HDU data, or write a new fits file. It's important to remember to preserve the ASDF extension because that contains the WCS information used by the pipeline for alignment. In this example, we are going to write new files with `bgsub` appended to the end fo the filename.\n",
    "\n",
    "The target folder is `'../bgnd_sub_imgs/'` but you can set it to anything you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac0615-bc26-4037-a884-69d66e38e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgsub_path = Path(\"../bgnd_sub_imgs/\")\n",
    "\n",
    "def write_bgsub(sci_file, img, path):\n",
    "    \"\"\"Write the background-subtracted version of a file to disk\"\"\"\n",
    "    sci_file = Path(sci_file)\n",
    "    bgsub_name = Path(path) / (sci_file.stem + '_bgsub' + sci_file.suffix)\n",
    "    with fits.open(sci_file) as hdulist:\n",
    "        hdus = [i.copy() for i in hdulist]\n",
    "    hdus[1].data = img\n",
    "    bgsub_hdulist = fits.HDUList(hdus)\n",
    "    bgsub_hdulist.writeto(bgsub_name, overwrite='True')\n",
    "    print(\"Wrote\", bgsub_name)\n",
    "for sci_file, img in bgnd_sub_imgs.items():\n",
    "    write_bgsub(datapath / sci_file, img, bgsub_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3d76f-3331-4643-ac59-11278d15bc3e",
   "metadata": {},
   "source": [
    "# Stage 3\n",
    "\n",
    "Replace the filenames in the Stage 3 association file with the background-subtracted filenames, or write your own Stage 3 association file -- which is what we will do here -- and run Stage 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9c229-236e-4215-948b-bed9ce22cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dummy_asn(filename, name, filedict):\n",
    "    \"\"\"\n",
    "    Write a dummy ASN file for manually processing files through Stage 3\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filedict: dict\n",
    "      dict where the key is the relative path and filename for the association\n",
    "      file, and the value is \"science\" or \"psf\"\n",
    "    name: prefix for the stage 3 output files\n",
    "    sci_files: list of str\n",
    "      list of paths to the science image files\n",
    "    psf_files: list of str\n",
    "      list of paths to the psf image files\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    association file written to given location\n",
    "\n",
    "    \"\"\"\n",
    "    # make the specifications for the image files\n",
    "    def make_entries(filedict, ntabs=3):\n",
    "        tab='\\t'\n",
    "        line = lambda key, val: f\"{tab*(ntabs+1)}\\\"expname\\\": \\\"{key}\\\",\\n{tab*(ntabs+1)}\\\"exptype\\\": \\\"{val}\\\"\"\n",
    "        lines = f\"\\n{tab*ntabs}}},{{\\n\".join(line(key, val) for key, val in filedict.items())\n",
    "        return lines\n",
    "    file_str = make_entries(filedict, 5)\n",
    "\n",
    "    template = f\"\"\"{{\n",
    "    \"asn_type\": \"coron3\",\n",
    "    \"asn_rule\": \"candidate_Asn_Lv3Coron\",\n",
    "    \"program\": \"{name}\",\n",
    "    \"asn_id\": \"c1001\",\n",
    "    \"target\": \"dummy\",\n",
    "    \"asn_pool\": \"{name}-pool\",\n",
    "    \"products\": [{{\n",
    "        \"name\": \"{name}\",\n",
    "        \"members\": [{{\n",
    "    {file_str}\n",
    "    }}]\n",
    "    }}]\n",
    "    }}\"\"\"\n",
    "    # make sure the file ends in .json\n",
    "    filename = Path(filename).with_suffix(\".json\")\n",
    "    with open(str(filename), 'w') as ff:\n",
    "        ff.write(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e823e-17c4-4d7b-905a-68a47260df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(bgsub_path.glob(\"jw*calints_bgsub.fits\"))\n",
    "obsnum_files = {f.name: f.name[7:10] for f in files}\n",
    "obsnum_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb284681-88db-4fe4-8f4d-9f8c168b882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory\n",
    "output_folder = \"pipeline_output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa74d6a-e7dd-4901-a8de-dbb4e86c954a",
   "metadata": {},
   "source": [
    "## 1065\n",
    "\n",
    "use the APT file to figure out which observation numbers correspond to the science target and which to the reference PSF target.\n",
    "For HIP 65426's F1140C observations, Observations 4 and 5 are the science, and 6 are the references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f909a3-5f16-4aea-9f41-2b73e08f165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci = {f: obsnum for f, obsnum in obsnum_files.items() if obsnum in ['019','020']}\n",
    "ref = {f: obsnum for f, obsnum in obsnum_files.items() if obsnum == '021'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d035f-80c4-4aa2-bbad-33f0f3e4a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6419fc6-ce28-44b5-a4f8-4d6d5b60682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736e06d-0c7c-4e9b-964a-9cdc965b8908",
   "metadata": {},
   "source": [
    "Copy the above filenames into a new association file and write it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed3eb6-611f-4ced-8946-44bc6ea585e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_file = \"./stage3_asn_hd141569a_1065.json\"\n",
    "\n",
    "# list the files and whether they are science or psf\n",
    "files = {}\n",
    "for f in sci.keys():\n",
    "    files[\"../bgnd_sub_imgs/\" + f] = 'science'\n",
    "for f in ref.keys():\n",
    "    files[\"../bgnd_sub_imgs/\" + f] = 'psf'\n",
    "write_dummy_asn(asn_file, \"01386_hd141569a_1065\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853e474-cd0a-4eec-8d70-424ef00d0cfc",
   "metadata": {},
   "source": [
    "Run Stage 3 with a hand-made association file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad235b-2a80-4cba-82e9-5d72ef4d05e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it's a disk target so we don't want to use many KLIP modes - set it to 1. Default is 50\n",
    "params = {'output_dir': \"../pipeline_output/\", # default is '.'\n",
    "          'steps': { # this is optional\n",
    "              'klip': {'truncate': 5}\n",
    "                   }\n",
    "         }\n",
    "cor3 = Coron3Pipeline.call(str(asn_file), **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd069f-36d3-4083-a5bf-27b5506cbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fits.getdata(\"../pipeline_output/01386_hd141569a_1065_i2d.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10783ba2-1401-4735-af4e-36bb83b46fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "vmin, vmax = np.quantile(img, [0.01, 0.99])\n",
    "ax.imshow(img, origin='lower', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7fe88-26f8-46b5-8da4-6bfdf4a3f4e4",
   "metadata": {},
   "source": [
    "## 1140\n",
    "For F1140C, Observations 22 and 23 are the science, and 24 are the references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e688869-9f45-464f-884c-7c4c83e35ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci = {f: obsnum for f, obsnum in obsnum_files.items() if obsnum in ['022','023']}\n",
    "ref = {f: obsnum for f, obsnum in obsnum_files.items() if obsnum == '024'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd333ec-62bc-495a-8966-588882023939",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c43e22-6a20-46ab-8142-c482ce73d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207d814-492b-4b2c-b949-001f991c669e",
   "metadata": {},
   "source": [
    "Copy the above filenames into a new association file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88637d6a-9c5f-42c5-a773-f76df959df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the files and whether they are science or psf\n",
    "files = {}\n",
    "for f in sci.keys():\n",
    "    files[\"../bgnd_sub_imgs/\" + f] = 'science'\n",
    "for f in ref.keys():\n",
    "    files[\"../bgnd_sub_imgs/\" + f] = 'psf'\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966d829-513a-4675-91f1-9c7c1dbaea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the asn file\n",
    "asn_file = \"./stage3_asn_hd141569a_1140.json\"\n",
    "\n",
    "write_dummy_asn(asn_file, \"01386_hd141569a_1140\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4276455-4822-4a30-8dd7-afd4e80ebcf1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it's a disk target so we don't want to use many KLIP modes - set it to 1. Default is 50\n",
    "params = {'output_dir': \"../pipeline_output/\", # default is '.'\n",
    "          'steps': { # this is optional\n",
    "              'klip': {'truncate': 1}\n",
    "                   }\n",
    "         }\n",
    "cor3 = Coron3Pipeline.call(str(asn_file), **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9a67e-2955-4fac-80ba-5863780c4775",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it's a disk target so we don't want to use many KLIP modes - set it to 1. Default is 50\n",
    "params = {'output_dir': \"../pipeline_output/\", # default is '.'\n",
    "          'steps': { # this is optional\n",
    "              'klip': {'truncate': 1}\n",
    "                   }\n",
    "}\n",
    "cor3 = Coron3Pipeline.call(str(asn_file), **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ff754-f0ad-416c-803f-21e2bf209cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fits.getdata(\"../pipeline_output/01386_hd141569a_1140_i2d.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358e75e-5859-46b9-8c3a-54b736a428f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "vmin, vmax = np.quantile(img, [0.01, 0.99])\n",
    "ax.imshow(img, origin='lower', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a7ff7-f399-46a6-a0ac-c4e3e3a27113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b804e3-0fa4-4405-8b8d-c848ef812442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jwst_inspector]",
   "language": "python",
   "name": "conda-env-jwst_inspector-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
