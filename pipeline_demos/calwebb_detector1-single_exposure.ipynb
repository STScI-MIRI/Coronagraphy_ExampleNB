{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2614abda-960a-48e7-97cd-3d240cc9c57e",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# calwebb_detector1 step-by-step notebook\n",
    "---\n",
    "**Author**: Jonathan Aguilar (jaguilar@stsci.edu) | **Latest Update**: 8 Nov 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e1f8b-43cf-42dd-ad09-96f68f69add4",
   "metadata": {},
   "source": [
    "* [Introduction](#intro)\n",
    "* [Pipeline Resources and Documentation](#resources)\n",
    "* [Non-pipeline imports](#imports)\n",
    "* [Convenience tools](#convenience_tools)\n",
    "* [Select the uncal file](#file_selection)\n",
    "* [Run the individual pipeline steps](#detector1_step_by_step)\n",
    "   * [Import the pipeline steps](#import_pipeline)\n",
    "   * [The `Data Quality Initialization` step](#dq_init)\n",
    "   * [The `Saturation Flagging` step](#saturation)\n",
    "   * [The `First Frame Correction` step](#firstframe)\n",
    "   * [The `Last Frame Correction` step](#lastframe)\n",
    "   * [The `Linearity Correction` step](#linearity)\n",
    "   * [The `Reset Switch Charge Decay Correction` step](#rscd)\n",
    "   * [The `Dark Current Subtraction` step](#dc)\n",
    "   * [The `Reference Pixel Subtraction` step](#refpix)\n",
    "   * [The `Cosmic Ray Flagging` step](#jump)\n",
    "   * [The `Ramp_Fitting` step](#ramp_fitting)\n",
    "   * [Saving to rate/rateints](#close_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4434da5-44e5-477b-9b65-7da71f9f891e",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "The Stage 1 JWST pipeline takes 4-D data in units of DN (Data Number, a unit used to label uncalibrated counts coming from the detector readout electronics), and performs various detector corrections to transform it into an uncalibrated 3-D slope cube (`_rateints.fits`) (or 2-D slope image, `_rate.fits`) with units of DN/sec. \n",
    "\n",
    "This notebook breaks the calwebb_detector1 (also called Detector1Pipeline) pipeline class into steps, runs each independently, and examines the output. It demonstrates how to change step-specific parameters at the step level. Much of the material, especially the documentation, is based on the example notebook found [here](https://github.com/spacetelescope/jwebbinar_prep/blob/main/pipeline_inflight/imaging_mode_stage_1.ipynb), written by Bryan Hilbert. Materials and videos can be found [here](https://www.stsci.edu/jwst/science-execution/jwebbinars) under JWebbinar 18. Here, it has been tailored to the specific case of MIRI coronagraphy.\n",
    "\n",
    "The primary purpose of this notebook is to provide an example of each Stage 1 step and how its parameters are set. Users can then easily modify a single step and examine its output without having to run the entire Stage1 pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea992ce-5505-4fc0-acc2-7a836970e242",
   "metadata": {},
   "source": [
    "<a id='resources'></a>\n",
    "## Pipeline resources and documentation\n",
    "\n",
    "Documentation on `calwebb_detector1` and the steps run on MIRI coronagraphy data specifically can be found here: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1\n",
    "\n",
    "We also refer the user to the Imaging example notebook: https://github.com/spacetelescope/jwebbinar_prep/blob/main/pipeline_inflight/imaging_mode_stage_1.ipynb. This contains a wealth of information that has been omitted here for brevity.\n",
    "\n",
    "For more pipeline notebooks, see the examples https://github.com/spacetelescope/jwebbinar_prep/tree/main/pipeline_inflight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020a8b2-954c-4091-b12e-ac4e1e19f5aa",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Non-pipeline imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e99c1-0a74-44b4-a48a-df8ff75a26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c204f4-30c2-4785-948f-631a847b8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db23daf-b763-44c5-8772-2c45c7f2ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385abb3f-ea84-43b1-9de8-0fa5a228ec8b",
   "metadata": {},
   "source": [
    "<a id='convenience_tools'></a>\n",
    "## Convenience tools\n",
    "\n",
    "Environment paths and functions that make life easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92478559-b2da-4cc1-b07b-7a93f1679415",
   "metadata": {},
   "source": [
    "First, set up a local CRDS directory. When the pipeline pulls a reference file from CRDS for the first time, it will write a copy to this directory. All subsequent reads of the reference file will redirect to the local directory instead of sending the file again over the network.\n",
    "\n",
    "See https://jwst-pipeline.readthedocs.io/en/latest/jwst/user_documentation/reference_files_crds.html#crds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8520fc8-21a4-44ba-9a17-61b867d060a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CRDS_PATH'] = '/Volumes/agdisk/crds/'\n",
    "# os.environ['CRDS_PATH'] = ''\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d1301-f083-48cb-8100-558cca0df1c5",
   "metadata": {},
   "source": [
    "Advanced users - uncomment the cell below and specify the context if you have a specific combination of reference files you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6ea1e-cf61-4a93-a2d2-dab17117c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CRDS_CONTEXT'] = 'jwst_1140.pmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c701d-f344-4513-8cd9-651246a07992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some plot formatting\n",
    "mpl.rcParams['image.origin'] = \"lower\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9e3c5-0632-4a1c-97ae-c4c39a754754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In my setup, this command needs to be run twice\n",
    "%matplotlib auto\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b8782-5e6c-44a5-bc9e-93520c61453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this helper function to map out a particular DQ flag will be useful\n",
    "# DQ flags can be found here: \n",
    "# https://jwst.readthedocs.io/en/latest/jwst/references_general/references_general.html#data-quality-flags\n",
    "def get_dq_flag(flag, dq_img):\n",
    "    \"\"\"return the pixels that have a given DQ flag\"\"\"\n",
    "    bad_bitvalue = dqflags.pixel[flag]\n",
    "    flags = np.bitwise_and(dq_img, bad_bitvalue).astype(bool)\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100c225-7f69-40ea-8949-8f8bee5fd4d9",
   "metadata": {},
   "source": [
    "<a id=\"file_selection\"></a>\n",
    "## Select the uncal file\n",
    "\n",
    "The cell below will retrieve Observation 7 of the High-contrast ERS program (PID 1386), from MAST. \n",
    "\n",
    "If you would like to use a different exposure, please direct the `uncal_file` variable to the desired file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f345d66-285a-43fb-8d19-a8f6772b04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Observations\n",
    "filename = \"jw01386007001_04101_00001_mirimage_uncal.fits\"\n",
    "Observations.download_file(f\"mast:JWST/product/{filename}\", local_path= f\"./uncal/{filename}\")\n",
    "uncal_file = f\"./uncal/{filename}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b0423-6cc4-4158-a424-e27581161a3d",
   "metadata": {},
   "source": [
    "Let's do a quick inspection of the file. We see it is 4 dimensional, with the last two axes representing detector x and y coordinates, and the first two representing each group, and each integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8eba88-29f8-437d-a7b4-d80b3bd94380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some basic information\n",
    "fits.info(uncal_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd0da8-8c38-4086-899c-5cca552a0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple plot - there isn't much to see yet\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "img = fits.getdata(uncal_file, 1)\n",
    "img = np.nanmean(img, axis=(0, 1))\n",
    "imlims = dict(zip(['vmin', 'vmax'], np.nanquantile(img, [0.1, 0.9])))\n",
    "ax.imshow(img, **imlims, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe6259-082a-46fe-a6b9-f124784551ad",
   "metadata": {},
   "source": [
    "<a id='detector1_step_by_step'></a>\n",
    "## Run each step of calwebb_detector1\n",
    "\n",
    "We're going to save the output of each step separately, so the code below generates an output folder for each step. We will be running only the steps that are relevant to the MIRI coronagraphy pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e6ce8e-2d57-44ec-b0de-c783ba6870b6",
   "metadata": {},
   "source": [
    "The steps, in order of execution, are:\n",
    "- `dq_init`\n",
    "    - data quality initialization\n",
    "    - populates the DQ mask for the input dataset\n",
    "    - no step-specific arguments\n",
    "    - reference file: MASK\n",
    "- `saturation`\n",
    "    - flags pixels at or below the A/D floor (< 0 DN) or above the saturation threshold\n",
    "    - no step-specific arguments\n",
    "    - reference file: SATURATION\n",
    "- `firstframe`\n",
    "    - only for MIRI; flags the first group in every integration as bad (sets DO_NOT_USE DQ bit)\n",
    "    - no step-specific arguments\n",
    "    - no reference file used\n",
    "- `lastframe`\n",
    "    - only for MIRI; flags the final group in each integration as bad (sets DO_NOT_USE DQ bit)\n",
    "    - no step-specific arguments\n",
    "    - no reference file used\n",
    "- `linearity`\n",
    "    - linearity correction\n",
    "    - correction is applied pixel-by-pixel, group-by-group, integration-by-integration within a science exposure\n",
    "    - no step-specific arguments\n",
    "    - reference file: LINEARITY\n",
    "- `rscd`\n",
    "    - Reset Switch Charge Decay (RSCD) Correction\n",
    "    - only for MIRI, and only applied after the first integration\n",
    "    - flags N groups as DO_NOT_USE if the charge in the reset switches has not sufficienty decayed?\n",
    "    - no step-specific arguments\n",
    "    - reference file: RSCD    \n",
    "- `dark_current`\n",
    "    - dark current subtraction\n",
    "    - subtracts dark current data stored in a dark reference file\n",
    "    - one step-specific argument:\n",
    "        - `dark_output filename`; saves the frame-averaged dark data to this file\n",
    "    - reference file: DARK    \n",
    "- `refpix`\n",
    "    - reference pixel correction\n",
    "    - uses reference pixels to correct for drifts in the readout amplifiers\n",
    "    - step arguments:\n",
    "        - `odd_even_columns bool [True]`; odd and even columns are treated separately\n",
    "        - `use_side_ref_pixels bool [True]`; only for NIR data\n",
    "        - `side_smoothing_length int [11]`: height of the window used for the running median calculation\n",
    "        - `side_gain float [1.0]` how much to multiply the side reference signal before subtraction\n",
    "        - `odd_even_rows bool [True]` calculate reference signal separately for odd and even rows; only for MIR\n",
    "    - reference file: DARK    \n",
    "- `jump`\n",
    "    - detects jumps in an exposure (after saturation step has been applied)\n",
    "    - looks for outliers in up-the-ramp read\n",
    "    - skips automatically if ngroups/integration < 3\n",
    "    - step-specific arguments:\n",
    "        - `rejection_threshold float [4.0]` sigma rejection threshold\n",
    "        - `maximum_cores string [none]` fraction of available cores to use\n",
    "        - `flag_4_neighbors bool [True]` if jump is detected, flag 4 neighbors as jumps too\n",
    "        - `max_jump_to_flag_neighbors float [200]` sigma threshold to limit automatic neighbor flagging (so they will be flagged as primary jumps, and *their* neighbors can be flagged\n",
    "        - `min_jump_to_flag_naighbors float [10]` limits flagging of neighbors of marginal jump detections.\n",
    "    - two reference files:\n",
    "        - GAIN\n",
    "        - READNOISE\n",
    "- `ramp_fitting`\n",
    "    - fits a line to the group data in the input file to determine the count rate\n",
    "    - step-specific arguments:\n",
    "        - `save_opt bool [False]` write optional output product\n",
    "        - `opt_name str` overrides the default name for the output product\n",
    "        - `int_name str` overrides the default name for the per-integration product\n",
    "        - `maximum_cores str [none]` fraction of cores to use for multiprocessing\n",
    "    - reference files: \n",
    "        - GAIN\n",
    "        - READNOISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a3a19-3bc1-4978-a6ec-c211f4738a35",
   "metadata": {},
   "source": [
    "<a id='import_pipeline'></a>\n",
    "### Import the pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680451a4-78e9-4b61-9ded-491f9494f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "jwst.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1f8e7-0f09-4823-b238-9b8612630a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst import datamodels\n",
    "from jwst.datamodels import dqflags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d3b74-aa57-4851-b80c-f2818fa25ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.dq_init import DQInitStep\n",
    "from jwst.saturation import SaturationStep\n",
    "from jwst.firstframe import FirstFrameStep\n",
    "from jwst.lastframe import LastFrameStep\n",
    "from jwst.linearity import LinearityStep\n",
    "from jwst.rscd import RscdStep\n",
    "from jwst.dark_current import DarkCurrentStep\n",
    "from jwst.refpix import RefPixStep\n",
    "from jwst.jump import JumpStep\n",
    "from jwst.ramp_fitting import RampFitStep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8dbe4-fb1a-4952-8aa7-b0634ed2992b",
   "metadata": {},
   "source": [
    "### Set up the output storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b453a-3764-443a-b215-caec6bfc2812",
   "metadata": {},
   "source": [
    "We're going to write out the results of each step to disk, and also keep a copy in memory in the `results` dict generated in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86729fe6-a0e9-4f41-a4dc-6cd32cac88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_pars() method returns a dictionary of allowed parameters for the pipeline stage, including\n",
    "# a dictionary of parameters for each step. We will use this dictionary to get a list of steps that will\n",
    "# index our results dictionary.\n",
    "results = OrderedDict([(step, None) for step in Detector1Pipeline().get_pars()['steps'].keys()])\n",
    "\n",
    "# clean out steps that are skipped by the coronagraphy pipeline\n",
    "results.pop(\"group_scale\")\n",
    "results.pop(\"ipc\")\n",
    "results.pop(\"superbias\") \n",
    "results.pop(\"reset\")\n",
    "results.pop(\"gain_scale\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5b57d-3953-4179-b033-246cbec38a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here is a list of the different steps:\")\n",
    "for step in results.keys():\n",
    "    print(\"\\t\" + step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb256a2f-b878-4761-ab77-cfb3c21a1426",
   "metadata": {},
   "source": [
    "For this notebook, each step will get its own output folder: `output/{step_name}`\n",
    "\n",
    "Generate the output folders specific to this notebook (do nothing if they already exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fb0d0-498f-4bcd-83dd-bc3acfc28aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parent = Path(f\"./stage1/output-steps/\")\n",
    "for k in results.keys():\n",
    "    p = output_parent / k\n",
    "    if not p.exists():\n",
    "        p.mkdir(parents=True)\n",
    "        print(str(p.resolve()), \"made\")\n",
    "    else:\n",
    "        print(f\"{str(p)} found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7102b-cde7-4111-9f59-545dff2edd8e",
   "metadata": {},
   "source": [
    "ASDF datamodels are the native data format used by the pipeline, so we're going to use them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed515a3d-610a-492a-b51c-4cdebbf2611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dm = datamodels.open(uncal_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6e436-c505-47aa-9d7e-0067669722a1",
   "metadata": {},
   "source": [
    "Add the starting data (\"uncal\") to the results dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee400a6a-28c6-4f3e-b4c0-9bb540b5ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['init'] = init_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ca409-f3fd-434e-a44f-41addec96dc1",
   "metadata": {},
   "source": [
    "<a id=\"dq_init\"></a>\n",
    "## DQ Init\n",
    "\n",
    "https://stdatamodels.readthedocs.io/en/latest/jwst/datamodels/index.html#data-models\n",
    "\n",
    "Populates the DQ header\n",
    "\n",
    "The dq_init step has no step-specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce889ca-725b-4a3c-8f84-e59ae80a1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"dq_init\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d38f9-2309-4918-bd0c-68032a23e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['dq_init'] = DQInitStep.call(\n",
    "    results['init'],\n",
    "    # common\n",
    "    save_results=True, \n",
    "    output_dir=str(output_dir)\n",
    "    # step-specific\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d5425-2599-4be8-b2d5-6acbe6546a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(results['dq_init'].data.shape == init_dm.data.shape)\n",
    "except AssertionError:\n",
    "    for k in ['init', 'dq_init']:\n",
    "        print(k, results[k].data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53753a0b-b782-41d4-9c9d-4d89b5c6c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=2, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle(\"Check that the DQ extension has been populated\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(f\"Pixel DQ flags\")\n",
    "\n",
    "img = results['dq_init'].pixeldq\n",
    "\n",
    "ax.imshow(img);\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(f\"Group DQ flags\")\n",
    "img = np.nanmax(results['dq_init'].groupdq, axis=(0, 1))\n",
    "ax.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02e7d8-604e-40e5-94fa-68829298892f",
   "metadata": {},
   "source": [
    "<a id=\"saturation\"></a>\n",
    "## Saturation\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/saturation/index.html#saturation-step\n",
    "\n",
    "The saturation step flags pixels at or below the A/D floor or above the saturation threshold. Pixels values are flagged as saturated if the pixel value is larger than the defined saturation threshold. Pixel values are flagged as below the A/D floor if they have a value of zero DN.\n",
    "\n",
    "The saturation step has one step-specific argument:\n",
    "- n_pix_grow_sat: (2xn + 1) the distance to use when growing saturation flag values to neighboring pixels, in order to account for charge migration (spilling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c7ef3-56a2-46ed-8997-8fbdc5ba002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"saturation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f346e27-85ff-448b-be40-62fa027100e5",
   "metadata": {},
   "source": [
    "Let's test two different values of `n_pix_grow_sat`: 1, and 5\n",
    "\n",
    "N.B. this step can take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff9e49-1b91-4882-a60a-44ee498e7624",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sat1 = SaturationStep.call(\n",
    "    results['dq_init'],\n",
    "    # common\n",
    "    save_results=True, \n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific arguments\n",
    "    n_pix_grow_sat = 1, # default is 1\n",
    ")\n",
    "sat5 = SaturationStep.call(\n",
    "    results['dq_init'],\n",
    "    # common\n",
    "    save_results=True, \n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific arguments\n",
    "    n_pix_grow_sat = 5, # default is 1\n",
    ")\n",
    "results['saturation'] = sat1 # use the default parameter moving forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcea568-a472-4e2f-8f0f-309dbaaec7b3",
   "metadata": {},
   "source": [
    "Check pixels for saturation flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dfa665-76f4-4536-9d09-c6ecf8a525e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the pixels flagged \"SATURATED\"\n",
    "dq_imgs = {}\n",
    "flag = \"SATURATED\"\n",
    "for s, satdm in [('sat1', sat1), ('sat5', sat5)]: \n",
    "    dq_imgs[s] = get_dq_flag(flag, satdm.groupdq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284883f9-e089-4c7d-b4a8-fd70726c285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for satval, dq_img in dq_imgs.items():\n",
    "    print(f\"{satval}: {dq_img[dq_img.astype(bool)].size:10d} pix flagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56467dd8-c192-49b0-ba40-5a81d63b0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(3*6, 1*6))\n",
    "fig.suptitle(\"Saturation flags\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Uncal Image [Mean]\")\n",
    "init_img = np.nanmean(init_dm.data, axis=(0, 1))\n",
    "vmin, vmax = np.nanquantile(init_img, [0.01, 0.99])\n",
    "ax.imshow(init_img, vmin=vmin, vmax=vmax)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"Box width: 2*1 + 1\")\n",
    "ax.imshow(dq_imgs['sat1'].any(axis=(0, 1)))\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Box width: 2*5 + 1\")\n",
    "ax.imshow(dq_imgs['sat5'].any(axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fce504-5079-4ef1-9a5d-2a30d593191c",
   "metadata": {},
   "source": [
    "<a id=\"firstframe\"></a>\n",
    "## First Frame Correction\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/firstframe/index.html#firstframe-step\n",
    "\n",
    "The MIRI first frame correction step flags the first group in every integration as bad (the “DO_NOT_USE” data quality flag is added to the GROUPDQ array), but only if the total number of groups per integration is greater than 3.\n",
    "\n",
    "The first frame correction has no step-specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf120f-d335-4b6c-8871-2cdcbf2285a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"firstframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9b5e0-40a7-4e29-8191-05485676f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['firstframe'] = FirstFrameStep.call(\n",
    "    results['saturation'],\n",
    "    # common\n",
    "    save_results=True, \n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific - None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe0521-3dc8-4d94-b931-302dea95c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the DO_NOT_USE flag\n",
    "donotuse = get_dq_flag(\"DO_NOT_USE\", results['firstframe'].groupdq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cf002-d2f6-4843-b691-951f51220b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "donotuse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f897760-d975-4f93-92cd-ecc917ca4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the first frame is flagged all DO_NOT_USE\n",
    "try:\n",
    "    assert(donotuse[:, 0].all())\n",
    "except AssertionError:\n",
    "    print(\"Error!! First frame is not flagged all DO_NOT_USE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16255f5e-1c76-4b73-a7a6-f2e6cdca8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the second frame is NOT flagged all DO_NOT_USE\n",
    "try:\n",
    "    assert(not donotuse[:, 1].all())\n",
    "except AssertionError:\n",
    "    print(\"Error!! Second frame *is* flagged all DO_NOT_USE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a506adc-cfed-41b1-beb3-d47969ddecdd",
   "metadata": {},
   "source": [
    "<a id='lastframe'></a>\n",
    "## Last Frame Correction\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/lastframe/index.html#lastframe-step\n",
    "\n",
    "Flags the final group in each integration as bad (the “DO_NOT_USE” bit is set in the GROUPDQ flag array), but only if the total number of groups in each integration is greater than 2.\n",
    "\n",
    "The last frame correction has no step-specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abb89e-bc66-417e-826c-e9489098d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"lastframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5715e-5b3a-4482-8728-b7a33a5bf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['lastframe'] = LastFrameStep.call(\n",
    "    results['firstframe'],\n",
    "    # common\n",
    "    save_results=True,\n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific - None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6598bbb-048f-4d6e-a389-d18ae5028259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the DO_NOT_USE flag\n",
    "donotuse = get_dq_flag(\"DO_NOT_USE\", results['lastframe'].groupdq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719d4e1-7dfb-46a8-a5d4-fe453cef92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the last frame is flagged all DO_NOT_USE\n",
    "try:\n",
    "    assert(donotuse[:, -1].all())\n",
    "except AssertionError:\n",
    "    print(\"Error!! Last frame is all DO_NOT_USE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5724b92-c26d-4844-bb31-166693793192",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 1, 4\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "fig.suptitle(\"First and last frame DQ check\\nMask flagged pixels\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"first DQ frame\")\n",
    "ax.imshow(donotuse[:, 0].any(axis=0))\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"last DQ frame\")\n",
    "ax.imshow(donotuse[:, -1].any(axis=0))\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"middle DQ frame\")\n",
    "ax.imshow(donotuse[:, 1].any(axis=0))\n",
    "\n",
    "ax = axes[3]\n",
    "ax.set_title(\"Data [mean]\")\n",
    "ax.imshow(np.nanmean(np.ma.masked_array(results['lastframe'].data, mask=donotuse), axis=(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370fd0e6-7afe-498c-9edf-d0857df4e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the second-to-last frame is NOT flagged all DO_NOT_USE\n",
    "try:\n",
    "    assert(not donotuse[:, -2].all())\n",
    "except AssertionError:\n",
    "    print(\"Error!! Second-to-last frame is all DO_NOT_USE.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7592ca3-ae3a-4676-9652-ff936c47568c",
   "metadata": {},
   "source": [
    "<a id='linearity'></a>\n",
    "## Linearity\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/linearity/index.html#linearity-step\n",
    "\n",
    "The linearity step applies the “classic” linearity correction adapted from the HST WFC3/IR linearity correction routine, correcting science data values for detector non-linearity.\n",
    "\n",
    "The linearity correction has no step-specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeaab5b-140c-4d90-90bc-76b7ca8af51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"linearity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9547e9b-b16f-4ff0-8e33-f104e9a6f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['linearity'] = LinearityStep.call(\n",
    "    results['lastframe'],\n",
    "    # common\n",
    "    save_results=True,\n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific - None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325dba0e-6b37-49e9-bbc5-0f9cc417761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ramps for 6 randomly chosen pixels\n",
    "npix = 6\n",
    "pixels = np.random.randint(15, 200, npix*2).reshape((npix, 2))\n",
    "ramps = {\n",
    "    step: \n",
    "    np.stack([[i[1:-1, p[0], p[1]] for p in pixels] for i in results[step].data])\n",
    "    for step in ['lastframe', 'linearity']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9077ec-4add-49c6-988a-5d08eadbc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot some groups\n",
    "\n",
    "nrows, ncols = 1, 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "\n",
    "fig.suptitle(f\"Ramps before and after linearity corr for {npix} randomly chosen pixels\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Ramps\")\n",
    "\n",
    "for ramp in np.stack(ramps['lastframe']):\n",
    "    ax.plot(ramp.T, color='C0')\n",
    "for ramp in np.stack(ramps['linearity']):\n",
    "    ax.plot(ramp.T, color='C1')\n",
    "\n",
    "ax.plot([], [], color='C0', label='before linearity correction')\n",
    "ax.plot([], [], color='C1', label='after linearity correction')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"Difference (After - Before)\")\n",
    "\n",
    "diff = np.stack(ramps['linearity']) - np.stack(ramps['lastframe'])\n",
    "colors = mpl.cm.Reds(np.linspace(0.2, 1, len(diff)))\n",
    "for i, ramp in enumerate(diff):\n",
    "    ax.plot(ramp.T, c=colors[i])\n",
    "    ax.plot([], label=f'int {i+1}', c=colors[i])    \n",
    "ax.legend()\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Ratio (After / Before)\")\n",
    "\n",
    "diff = np.stack(ramps['linearity']) / np.stack(ramps['lastframe'])\n",
    "colors = mpl.cm.Reds(np.linspace(0.2, 1, len(diff)))\n",
    "for i, ramp in enumerate(diff):\n",
    "    ax.plot(ramp.T, c=colors[i])\n",
    "    ax.plot([], label=f'int {i+1}', c=colors[i])    \n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0622e3-ef10-4054-975a-72b253f3fc8c",
   "metadata": {},
   "source": [
    "<a id='rscd'></a>\n",
    "## Rscd\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/rscd/index.html#rscd-st\n",
    "\n",
    "The Reset Switch Charge Decay (RSCD) step corrects for some electronics effects by simply flagging the first N groups as DO_NOT_USE. \n",
    "\n",
    "The rscd correction has no step-specific arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b313a-1391-4892-9e79-536a93548207",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"rscd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2779694-89cb-47b8-8100-8f15bff20439",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['rscd'] = RscdStep.call(\n",
    "    results['linearity'], \n",
    "    # common\n",
    "    save_results=True,\n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific - None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d538b-5425-4be5-ad84-975a599d8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnu_count = {}\n",
    "for step in ['linearity', 'rscd']:\n",
    "    flagmap = get_dq_flag('DO_NOT_USE', results[step].groupdq)\n",
    "    dnu_count[step] = flagmap\n",
    "for step, flagmap in dnu_count.items():\n",
    "    print(f\"{step:10s}: {flagmap[flagmap.astype(bool)].size:10d} DO_NOT_USE pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cf45b-d07b-4305-abdb-161a5017c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot some groups\n",
    "nrows, ncols = 1, 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "fig.suptitle(\"Distribution of DO_NOT_USE in groups 1-4\\nRSCD should be all 1\")\n",
    "\n",
    "vmin, vmax= 0, 1\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Linearity DNU\")\n",
    "ax.imshow(dnu_count['linearity'][:, 1:4].astype(bool).any(axis=(0, 1)), vmin=0, vmax=1)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"RSCD DNU\")\n",
    "ax.imshow(dnu_count['rscd'][:, 1:4].astype(bool).any(axis=(0, 1)), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573f126-52a5-497b-b006-3574ccb1a941",
   "metadata": {},
   "source": [
    "<a id='dc'></a>\n",
    "## Dark Current\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/dark_current/index.html#dark-current-step\n",
    "\n",
    "The dark current step removes dark current from an exposure by subtracting dark current data stored in a dark reference file in CRDS.\n",
    "\n",
    "The dark current step has one step-specific argument:\n",
    "- \"dark_output\": file to save the frame-averaged dark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63650f-4a7e-4fc4-afa5-53941b608ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"dark_current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850191b-ed84-4742-9ca5-4c9b81cbe6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['dark_current'] = DarkCurrentStep.call(\n",
    "    results['rscd'], \n",
    "    # common\n",
    "    save_results=True, \n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific\n",
    "    dark_output= output_dir / \"dark.fits\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a246788-8158-4d39-9531-31f36afed9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ramps for 6 randomly chosen pixels\n",
    "npix = 6\n",
    "pixels = np.random.randint(15, 200, npix*2).reshape((npix, 2))\n",
    "ramps = {\n",
    "    step: \n",
    "    np.stack([[i[1:-1, p[0], p[1]] for p in pixels] for i in results[step].data])\n",
    "    for step in ['rscd', 'dark_current']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb81c2-0e63-401d-a7ab-ecf369d70962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot some groups\n",
    "\n",
    "nrows, ncols = 1, 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "\n",
    "fig.suptitle(f\"Ramps before and after dark corr for {npix} randomly chosen pixels\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Ramps\")\n",
    "\n",
    "for ramp in np.stack(ramps['rscd']):\n",
    "    ax.plot(ramp.T, color='C0')\n",
    "for ramp in np.stack(ramps['dark_current']):\n",
    "    ax.plot(ramp.T, color='C1')\n",
    "\n",
    "ax.plot([], [], color='C0', label='before dark correction')\n",
    "ax.plot([], [], color='C1', label='after dark correction')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"Difference (After - Before)\")\n",
    "\n",
    "diff = np.stack(ramps['dark_current']) - np.stack(ramps['rscd'])\n",
    "colors = mpl.cm.magma_r(np.linspace(0.2, 1, len(diff)))\n",
    "for i, ramp in enumerate(diff):\n",
    "    ax.plot(ramp.T, c=colors[i])\n",
    "\n",
    "ax.plot([], label=f'int 1', c=colors[0])\n",
    "ax.plot([], label=f'int {len(diff)}', c=colors[-1])    \n",
    "ax.legend()\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Ratio (After / Before)\")\n",
    "\n",
    "diff = np.stack(ramps['dark_current']) / np.stack(ramps['rscd'])\n",
    "colors = mpl.cm.magma_r(np.linspace(0.2, 1, len(diff)))\n",
    "for i, ramp in enumerate(diff):\n",
    "    ax.plot(ramp.T, c=colors[i])\n",
    "ax.plot([], label=f'int 1', c=colors[0])\n",
    "ax.plot([], label=f'int {len(diff)}', c=colors[-1])    \n",
    "ax.legend()\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.set_xlabel(\"Group #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e2886-08b4-49d8-86d9-bd137f157c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "268d9926-af49-4bc7-a437-bb2ae86a353c",
   "metadata": {},
   "source": [
    "<a id=\"refpix\"></a>\n",
    "## Refpix\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/refpix/index.html#refpix-step\n",
    "\n",
    "The refpix step corrects for drifts by using the reference pixels.\n",
    "\n",
    "Step-specific parameters:\n",
    "- odd_even_rows: True\n",
    "    - The reference signal is calculated and applied separately for even- and odd-numbered rows. MIR data only.\n",
    "- The following arguments do not apply to MIR data\n",
    "    - odd_even_columns: True\n",
    "        - Odd/Even columns are corrected separately. NIR data only.\n",
    "    - use_side_ref_pixels: True\n",
    "        - Side reference pix are used to correct by row. NIR data only.\n",
    "    - side_smoothing_length: 11\n",
    "        - The height of the window used in calculating the running median when calculating the side reference signal.\n",
    "    - side_gain: 1.0\n",
    "        - The factor that the side reference signal is multiplied by before subtracting from the group row-by-row..\n",
    "    - ovr_corr_mitigation_ftr: 1.8\n",
    "        - Avoid overcorrection of intermittently bad reference pixels in the IRS2 algorithm. NIRSpec/IRS2 data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e6f76-eaf3-44a7-9911-8b887e72f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"refpix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44bcdb-493c-404b-b403-ad997e3aae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['refpix'] = RefPixStep.call(\n",
    "    results['dark_current'], \n",
    "    # common\n",
    "    save_results=True,\n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific\n",
    "    odd_even_rows = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438020cf-71f2-4851-9f63-d70223496a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "donotuse = get_dq_flag(\"DO_NOT_USE\", results['refpix'].groupdq)\n",
    "\n",
    "# donotuse = dq_tools.separate_dq_flags(results['refpix'].groupdq.copy(), 'DO_NOT_USE')['DO_NOT_USE']\n",
    "refpix_masked = np.ma.masked_array(results['refpix'].data, mask=donotuse)\n",
    "dc_masked = np.ma.masked_array(results['dark_current'].data, mask=donotuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193948e-8fe4-4d9c-8a49-469bf0af36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 1, 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "fig.suptitle(\"Reference pixel correction is skipped for MIRI subarrays\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"RefPix\")\n",
    "ax.imshow(np.nanmean(refpix_masked[:, 1:-1], axis=(0, 1))\n",
    "         )\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"RefPix - DarkCurrent\")\n",
    "ax.imshow(np.nanmean(refpix_masked - dc_masked, axis=(0, 1))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e0553-65e5-424e-8a7b-9651a1cb3484",
   "metadata": {},
   "source": [
    "<a id='jump'></a>\n",
    "## Jump\n",
    "\n",
    "N.B. this step can take a while, especially if you have \"maximum_cores\" set to None. If you're running on a personal laptop, consider using \"half\". \n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/jump/index.html#jump-step\n",
    "\n",
    "Detects jumps in the ramp and sets flags in the DQ array\n",
    "\n",
    "30 optional arguments that can be set by the user:\n",
    "\n",
    "- rejection_threshold: 4.0\n",
    "    - A floating-point value that sets the sigma threshold for jump detection\n",
    "- three_group_rejection_threshold: 6.0\n",
    "    - Cosmic ray sigma rejection threshold for ramps having 3 groups\n",
    "- four_group_rejection_threshold: 5.0\n",
    "    - Cosmic ray sigma rejection threshold for ramps having 4 groups\n",
    "- maximum_cores: 'none'\n",
    "    - The number of available cores that will be used for multi-processing in this step. \n",
    "    - integer, 'quarter', 'half', 'all', 'none'\n",
    "- flag_4_neighbors: True\n",
    "    - will cause the four perpendicular neighbors of all detected jumps to also be flagged as a jump. This is needed because of the inter-pixel capacitance (IPC).\n",
    "- max_jump_to_flag_neighbors: 1000.0\n",
    "    - Any jump above this cutoff will not have its neighbors flagged\n",
    "- min_jump_to_flag_neighbors: 10.0\n",
    "    - Any primary jump below this value will not have its neighbors flagged.\n",
    "- after_jump_flag_dn1: 0.0\n",
    "- after_jump_flag_time1: 0.0\n",
    "    - After a jump of at least ‘after_jump_flag_dn1’ DN, groups up to ‘after_jump_flag_time1’ seconds will also be flagged as jumps.\n",
    "- after_jump_flag_dn2: 0.0\n",
    "- after_jump_flag_time2: 0.0\n",
    "    - after a jump of at least ‘after_jump_flag_dn2’ DN, groups up to ‘after_jump_flag_time2’ seconds will also be flagged as jumps.\n",
    "- min_sat_area: 1.0\n",
    "    - The minimum number of saturated pixels required to meet “sat_required_snowball”.\n",
    "- min_jump_area: 5.0\n",
    "    - The minimum number of contiguous pixels needed to trigger the expanded flagging of large cosmic rays events.\n",
    "- expand_factor: 2.0\n",
    "    - A multiplicative factor applied to the enclosing ellipse for snowballs\n",
    "- use_ellipses: False\n",
    "    - deprecated\n",
    "- sat_required_snowball: True\n",
    "    - requires that there are saturated pixels within the enclosed jump circle.\n",
    "- min_sat_radius_extend: 2.5\n",
    "    - The minimum radius of the saturated core of a snowball required to for the radius of the saturated core to be extended.\n",
    "- sat_expand: 2\n",
    "    - Number of pixels to add to the radius of the saturated core of snowballs\n",
    "- expand_large_events: False\n",
    "    - controls whether the jump step will expand the number of pixels that are flagged around large cosmic ray events\n",
    "- find_showers: False\n",
    "    - Turn on the detection of showers for the MIRI detectors\n",
    "- edge_size: 25\n",
    "    - The distance from the edge of the detector where saturated cores are not required for snowball detection\n",
    "- extend_snr_threshold: 1.2\n",
    "    - The SNR minimum for the detection of faint extended showers in MIRI\n",
    "- extend_min_area: 90\n",
    "    - The required minimum area of extended emission after convolution for the detection of showers in MIRI\n",
    "- extend_inner_radius: 1.0\n",
    "    - The inner radius of the ring_2D_kernel that is used for the detection of extended emission in showers\n",
    "- extend_outer_radius: 2.6\n",
    "    - The outer radius of the ring_2D_kernel that is used for the detection of extended emission in showers\n",
    "- extend_ellipse_expand_ratio: 1.1\n",
    "    - ultiplicative factor to expand the radius of the ellipse fit to the detected extended emission in MIRI showers\n",
    "- time_masked_after_shower: 15.0\n",
    "    - Number of seconds to flag groups as jump after a detected extended emission in MIRI showers\n",
    "- max_extended_radius: 200\n",
    "    - he maxiumum extension of the jump and saturation that will be flagged for showers or snowballs\n",
    "- minimum_groups: 3\n",
    "    - he minimum number of groups to run the jump step with sigma clipping\n",
    "- minimum_sigclip_groups: 100\n",
    "    - The minimum number of groups to switch the jump detection to use sigma clipping\n",
    "- only_use_ints: True\n",
    "    - If true the sigma clipping is applied only for a given group across all ints. If not, all groups from all ints are used for the sigma clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11895c5b-467b-4230-826b-c495786f584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"jump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4eb78c-6f0f-4dec-a0ce-d7b084143d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['jump'] = JumpStep.call(\n",
    "    results['refpix'], \n",
    "    # common\n",
    "    save_results=True,\n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific\n",
    "    rejection_threshold = 4.0,\n",
    "    three_group_rejection_threshold = 6.0,\n",
    "    four_group_rejection_threshold = 5.0,\n",
    "    maximum_cores = 'half', # this is the only one I have changed\n",
    "    flag_4_neighbors = True,\n",
    "    max_jump_to_flag_neighbors = 1000.0,\n",
    "    min_jump_to_flag_neighbors = 10.0,\n",
    "    after_jump_flag_dn1 = 0.0,\n",
    "    after_jump_flag_time1 = 0.0,\n",
    "    after_jump_flag_dn2 = 0.0,\n",
    "    after_jump_flag_time2 = 0.0,\n",
    "    min_sat_area = 1.0,\n",
    "    min_jump_area = 5.0,\n",
    "    expand_factor = 2.0,\n",
    "    use_ellipses = False,\n",
    "    sat_required_snowball = True,\n",
    "    min_sat_radius_extend = 2.5,\n",
    "    sat_expand = 2,\n",
    "    expand_large_events = False,\n",
    "    find_showers = False,\n",
    "    edge_size = 25,\n",
    "    extend_snr_threshold = 1.2,\n",
    "    extend_min_area = 90,\n",
    "    extend_inner_radius = 1.0,\n",
    "    extend_outer_radius = 2.6,\n",
    "    extend_ellipse_expand_ratio = 1.1,\n",
    "    time_masked_after_shower = 15.0,\n",
    "    max_extended_radius = 200,\n",
    "    minimum_groups = 3,\n",
    "    minimum_sigclip_groups = 100,\n",
    "    only_use_ints = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6967f5d-7a7a-48e0-aef6-5c315b4fe75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpflags = {step: get_dq_flag('JUMP_DET', results['jump'].groupdq) for step in ['refpix', 'jump']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039dc02-336e-45e9-adce-509d9d6ee662",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 1, 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6*ncols, 6*nrows))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Before Jump Flags\")\n",
    "ax.imshow(jumpflags['refpix'].any(axis=(0, 1))\n",
    "         )\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"After Jump Flags\")\n",
    "ax.imshow(jumpflags['jump'].any(axis=(0, 1))\n",
    "         )\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Differences\")\n",
    "ax.imshow(jumpflags['jump'].any(axis=(0, 1)) == jumpflags['refpix'].any(axis=(0, 1))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38642da-2d24-4594-9b5e-8912ef08c2b6",
   "metadata": {},
   "source": [
    "It appears no jumps were flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee77b00-62f0-454c-9902-42e77093a2a3",
   "metadata": {},
   "source": [
    "<a id=\"ramp_fitting\"></a>\n",
    "## Ramp Fit\n",
    "\n",
    "N.B. This is another step where it is advised to set `maximum_cores` to \"half\" or \"all\".\n",
    "\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/ramp_fitting/index.html#ramp-fitting-step\n",
    "\n",
    "This step determines the mean count rate, in units of counts per second, for each pixel by performing a linear fit to the data in the input file.\n",
    "\n",
    "- save_opt: False \n",
    "  - A True/False value that specifies whether to write the optional output product. Default is False.\n",
    "- opt_name: ''\n",
    "  - A string that can be used to override the default name for the optional output product.\n",
    "- int_name: ''\n",
    "  - A string that can be used to override the default name for the per-integration product.\n",
    "- suppress_one_group: True\n",
    "  - A boolean to suppress computations for saturated ramps with only one good (unsaturated) sample. The default is set to True to suppress these computations, which will compute all values for the ramp the same as if the entire ramp were saturated.\n",
    "- maximum_cores: None\n",
    "  - The fraction of available cores that will be used for multi-processing in this step. The default value is ‘none’ which does not use multi-processing. The other options are ‘quarter’, ‘half’, and ‘all’. Note that these fractions refer to the total available cores and on most CPUs these include physical and virtual cores. The clock time for the step is reduced almost linearly by the number of physical cores used on all machines. For example, on an Intel CPU with six real cores and 6 virtual cores setting maximum_cores to ‘half’ results in a decrease of a factor of six in the clock time for the step to run. Depending on the system the clock time can also decrease even more with maximum_cores is set to ‘all’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3563a-caea-4f1e-914d-dc1cce040798",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_parent / \"ramp_fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3510bdd-5f66-4261-9028-79b018d4fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ramp_fit'] = RampFitStep.call(\n",
    "    results['jump'], \n",
    "    # common\n",
    "    save_results=True, \n",
    "    output_dir=str(output_dir),\n",
    "    # step-specific\n",
    "    save_opt = False,\n",
    "    opt_name = '',\n",
    "    int_name = '',\n",
    "    suppress_one_group = True,\n",
    "    maximum_cores = 'half'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624e255-3131-40d2-803a-c43228f086b2",
   "metadata": {},
   "source": [
    "<a id='close_out'></a>\n",
    "## Close it out\n",
    "\n",
    "Just so that we can end up with the proper *rate{ints}.fits* filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f293a8-3a81-46c4-b193-71a564664069",
   "metadata": {},
   "outputs": [],
   "source": [
    "det1 = Detector1Pipeline(output_dir=str(output_parent))\n",
    "\n",
    "det1.save_model(results['ramp_fit'][0], \n",
    "                suffix=\"rate\",\n",
    "                output_file=results['ramp_fit'][0].meta.filename.split(\"_0_\")[0])\n",
    "\n",
    "det1.save_model(results['ramp_fit'][1], \n",
    "                suffix=\"rateints\",\n",
    "                output_file=results['ramp_fit'][1].meta.filename.split(\"_1_\")[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jwst_inspector]",
   "language": "python",
   "name": "conda-env-jwst_inspector-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
